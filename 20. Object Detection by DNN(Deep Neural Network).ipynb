{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 모델.\n",
    "model_name = 'opencv_data/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "\n",
    "# 모델 내의 신경망 구조 정보 파일명.\n",
    "prototxt_name = 'opencv_data/deploy.prototxt.txt'\n",
    "\n",
    "# 얼굴이라고 인정할 최소 정확도.\n",
    "min_confidence = 0.141\n",
    "\n",
    "# 사용할 파일명.\n",
    "file_name = 'opencv_data/image/marathon_01.jpg'\n",
    "\n",
    "# 이미지 읽기.\n",
    "img = cv2.imread(file_name)\n",
    "# cv2.imshow('Original Image', img)\n",
    "\n",
    "# 원본 이미지의 가로 세로 길이.\n",
    "height, width = img.shape[0:2]\n",
    "\n",
    "# 얼굴 인식 작업.\n",
    "# 사용할 모델 불러오기.\n",
    "model = cv2.dnn.readNetFromCaffe(prototxt_name, model_name)\n",
    "\n",
    "# prototxt 파일 이미지가 300 X 300, 3채널로 설정되어 있으므로 이에 맞춰 변환.\n",
    "cvt = cv2.resize(img, (300, 300))\n",
    "# cv2.imshow('Cvt', cvt)\n",
    "\n",
    "# 2진 데이터로 변환.\n",
    "# 원본 이미지 데이터, 스케일링(크기 조정), 결과 데이터 행렬 사이즈, 표준화를 위해 각 생상에서 빼줄 색상값.\n",
    "blob = cv2.dnn.blobFromImage(cvt, 1, (300,300), (104, 177, 123))\n",
    "# print(blob)\n",
    "\n",
    "# 학습 모델에 데이터를 입력.\n",
    "model.setInput(blob)\n",
    "\n",
    "# 얼굴 부분 인식.\n",
    "detection = model.forward()\n",
    "# Index[2] : 200 이 부분이 얼굴로 인식된 부분, 즉 200 군데가 얼굴로 인식된 것을 의미.\n",
    "# print(detection.shape)\n",
    "\n",
    "# 얼굴이라고 인식된 부분의 개수만큼 반복.\n",
    "for i in range(0, detection.shape[2]):\n",
    "    confidence = detection[0, 0, i, 2]\n",
    "    # 각 영역의 얼굴이라고 판단한 예측 정확도 확률.\n",
    "    # print(confidence)\n",
    "    \n",
    "    # 설정한 최소 정확도 보다 높은 것만 이용.\n",
    "    if confidence > min_confidence :\n",
    "    \n",
    "        # 얼굴이라고 인식된 영역의 데이터를 추출.\n",
    "        box1 = detection[0, 0, i, 3:7]\n",
    "        # print(box1)\n",
    "\n",
    "        # 원본 이미지에 맞게 좌표를 계산.\n",
    "        box2 = box1*np.array([width, height]*2)\n",
    "        # print(box2)\n",
    "\n",
    "        # 좌표를 정수(int) 형태로 변환.\n",
    "        x1, y1, x2, y2 = box2.astype('int')\n",
    "        # print(x1, y1, x2, y2)\n",
    "\n",
    "        # 사각형 생성.\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # 예측 정확도 표시.\n",
    "        text = f'{int(confidence*100)}%'\n",
    "        cv2.putText(img, text, (x1, y1), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "cv2.imshow('Detection', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='opencv_image/capcher1.PNG'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 파일명.\n",
    "file = 'opencv_data/video/obama_01.mp4'\n",
    "\n",
    "# 얼굴이라고 인정할 최소 정확도.\n",
    "min_confidence = 0.5\n",
    "\n",
    "# 영상 재생.\n",
    "cap = cv2.VideoCapture(file)\n",
    "\n",
    "while True :\n",
    "    ret, Frame = cap.read()\n",
    "    if Frame is None :\n",
    "        break\n",
    "        \n",
    "    cvt = cv2.resize(Frame,(300, 300))\n",
    "    blob = cv2.dnn.blobFromImage(cvt, 1, (300,300), (104, 177, 123))\n",
    "    model.setInput(blob)\n",
    "    detection = model.forward()\n",
    "    \n",
    "    for i in range(0, detection.shape[2]):\n",
    "        \n",
    "        confidence = detection[0,0,i,2]\n",
    "        if confidence > min_confidence :\n",
    "            Height, Width = Frame.shape[0:2]\n",
    "            Box1 = detection[0,0,i,3:7]\n",
    "            Box2 = Box1*np.array([Width, Height]*2)\n",
    "            x1, y1, x2, y2 = Box2.astype('int')  \n",
    "            cv2.rectangle(Frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            text = f'{int(confidence*100)}%'\n",
    "            cv2.putText(Frame, text, (x1, y1), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    cv2.imshow('Test', Frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') :\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='opencv_image/capture.PNG'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
