{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 읽기.\n",
    "# img = cv2.imread('opencv_data/image/marathon_01.jpg')\n",
    "# img = cv2.imread('opencv_data/image/marathon_02.jpg')\n",
    "# img = cv2.imread('opencv_data/image/marathon_03.jpg')\n",
    "img = cv2.imread('opencv_data/image/soccer_01.jpg')\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height   : 462\n",
      "width    : 820\n",
      "channels : 3\n"
     ]
    }
   ],
   "source": [
    "# 이미지 정보.\n",
    "print(f'height   : {img.shape[0]}')\n",
    "print(f'width    : {img.shape[1]}')\n",
    "print(f'channels : {img.shape[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haar Classifier 사용을 위한 cascade 파일.\n",
    "# Haar Object detection은 학습을 통해 구해진 가중치와 레이어의 구조가 정의되어 있는 파일을 불러와 사물을 인식하는 형태로 동작.\n",
    "# 즉, 학습과정은 존재하지 않고 작업속도가 바르지만 인지하지 못하는 사물들이 존재할 수 있음.\n",
    "\n",
    "face_cascade_name = 'opencv_data/haarcascades/haarcascade_frontalface_alt.xml'\n",
    "eyes_cascade_name = 'opencv_data/haarcascades/haarcascade_eye_tree_eyeglasses.xml'\n",
    "\n",
    "# casecadeClassifier 생성.\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "eyes_cascade= cv2.CascadeClassifier()\n",
    "\n",
    "# 각 분류기에 cascade 파일을 지정.\n",
    "face_cascade.load(cv2.samples.findFile(face_cascade_name))\n",
    "eyes_cascade.load(cv2.samples.findFile(eyes_cascade_name))\n",
    "\n",
    "# 인지율을 높이기 위해 사용할 이미지를 그레이 스케일로 변환.\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 인식률 향상을 위해 이미지 표준화.\n",
    "gray = cv2.equalizeHist(gray)\n",
    "\n",
    "# cv2.imshow('Face detection', gray)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# Face 인식.\n",
    "# 인식된 부분은 이미지 상의 좌축 상단 지점 x, y 좌표와 가로 세로 길이로 반환.\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "# 세로 가로 위치, 세로 가로 크기.\n",
    "# print(faces) ㅡ\n",
    "\n",
    "# 인식한 얼굴의 수 만큼 반복.\n",
    "for x, y, w, h in faces :\n",
    "    \n",
    "    # 인식한 얼굴을 사각형으로 그려줌.\n",
    "    # 이미지, 네모의 좌측 상단점, 네무의 우측 하단점, 색상, 두께\n",
    "    frame = cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 4)\n",
    "    \n",
    "    # 눈을 찾기 위해 얼굴 데이터만을 가져옴.\n",
    "    faceROI = gray[y:y+h, x:x+w]\n",
    "    \n",
    "    # 추출한 얼굴 데이터로부터 눈을 인식.\n",
    "    eyes = eyes_cascade.detectMultiScale(faceROI)\n",
    "    # print(eyes)\n",
    "    \n",
    "    # 인식한 눈을 동그라미로 표시. \n",
    "    for x2, y2, w2, h2 in eyes :\n",
    "        \n",
    "        # 눈의 중심정.\n",
    "        eye_center = x + x2 + w2//2, y + y2 + h2//2\n",
    "        \n",
    "        # 반경을 계산.\n",
    "        radius = int(round(w2+h2)*.25)\n",
    "        \n",
    "        # 원을 그림.\n",
    "        frame = cv2.circle(img, eye_center, radius, (0, 0, 255), 3)\n",
    "        \n",
    "cv2.imshow('Detection', frame)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Haar 분류기로는 작은 눈을 잘 못 찾는 단점이 존재.\n",
    "# 직접 학습 시킨 모델을 적용시켜 볼 필요도 있어보임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 파일 읽기.\n",
    "file = 'opencv_data/video/obama_01.mp4'\n",
    "# file = 'opencv_data/video/son_01.mp4'\n",
    "# file = 'opencv_data/video/son_02.mp4'\n",
    "# file = 'opencv_data/video/tedy_01.mp4'\n",
    "cap = cv2.VideoCapture(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True :\n",
    "    # 영상 프레임 읽기.\n",
    "    ret, frame = cap.read()\n",
    "    # print(frame)\n",
    "    \n",
    "    # 더 이상 읽어온 영상이 없다면 중단.\n",
    "    if frame is None :\n",
    "        break\n",
    "\n",
    "    # 추출한 이미지를 그레이 스케일.\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 그레이 스케일 이미지 표준화.\n",
    "    gray =cv2.equalizeHist(gray)\n",
    "    \n",
    "    # 얼굴 인식.\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    # print(faces)\n",
    "    \n",
    "    for x, y, w, h in faces :\n",
    "    \n",
    "        # 인식한 얼굴을 사각형으로 그려줌.\n",
    "        # 이미지, 네모의 좌측 상단점, 네무의 우측 하단점, 색상, 두께\n",
    "        frame = cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 4)\n",
    "\n",
    "        # 눈을 찾기 위해 얼굴 데이터만을 가져옴.\n",
    "        faceROI = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # 추출한 얼굴 데이터로부터 눈을 인식.\n",
    "        eyes = eyes_cascade.detectMultiScale(faceROI)\n",
    "        # print(eyes)\n",
    "    \n",
    "        # 인식한 눈을 동그라미로 표시. \n",
    "        for x2, y2, w2, h2 in eyes :\n",
    "\n",
    "            # d원의 중심점.\n",
    "            eye_center = x + x2 + w2//2, y + y2 + h2//2\n",
    "\n",
    "            # 반경을 계산.\n",
    "            radius = int(round(w2+h2)*.25)\n",
    "\n",
    "            # 원을 그림.\n",
    "            frame = cv2.circle(frame, eye_center, radius, (0, 0, 255), 3)\n",
    "\n",
    "    # 표현.\n",
    "    cv2.imshow('Face detection', frame)\n",
    "    \n",
    "    # q키를 누르면 중단.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') :\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
